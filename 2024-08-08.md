A single neuron have an:
input values -> weights -> linear function -> activation function -> output value

**Linear function**
Sum of all values weights multiplication plus bias

F = W1 * X1 + W2 * X2 ... Wn * Xn + b 

Wi - weights on each input 
Xi - input value
b - bias the nut of which we configure neurons

**Activation function**
Squeezes what came out of linear function

can be sigmoid, tanh, softmax e.t.

![](Pasted%20image%2020240808185618.png)

